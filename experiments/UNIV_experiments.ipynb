{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8585402,
          "sourceType": "datasetVersion",
          "datasetId": 5134904
        }
      ],
      "dockerImageVersionId": 30716,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PĘTLA TRENINGOWA"
      ],
      "metadata": {
        "id": "SDEGEw2pb0cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the model\n",
        "\n",
        "model = social_stgcnn(n_stgcnn =args.n_stgcnn,n_txpcnn=args.n_txpcnn,\n",
        "output_feat=args.output_size,seq_len=args.obs_seq_len,\n",
        "kernel_size=args.kernel_size,pred_seq_len=args.pred_seq_len)\n",
        "\n",
        "\n",
        "#Training settings\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(),lr=args.lr)\n",
        "\n",
        "if args.use_lrschd:\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_sh_rate, gamma=0.1)\n",
        "\n",
        "\n",
        "\n",
        "checkpoint_dir = './checkpoint/'+args.tag+'/'\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "with open(checkpoint_dir+'args.pkl', 'wb') as fp:\n",
        "    pickle.dump(args, fp)\n",
        "\n",
        "\n",
        "\n",
        "print('Data and model loaded')\n",
        "print('Checkpoint dir:', checkpoint_dir)\n",
        "\n",
        "#Training\n",
        "metrics = {'train_loss':[],  'val_loss':[]}\n",
        "constant_metrics = {'min_val_epoch':-1, 'min_val_loss':9999999999999999}\n",
        "\n",
        "def train(epoch):\n",
        "    global metrics,loader_train\n",
        "    model.train()\n",
        "    loss_batch = 0\n",
        "    batch_count = 0\n",
        "    is_fst_loss = True\n",
        "    loader_len = len(loader_train)\n",
        "    turn_point =int(loader_len/args.batch_size)*args.batch_size+ loader_len%args.batch_size -1\n",
        "\n",
        "\n",
        "    for cnt,batch in enumerate(loader_train):\n",
        "        batch_count+=1\n",
        "\n",
        "        #Get data\n",
        "        batch = [tensor for tensor in batch]\n",
        "        obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\\\n",
        "         loss_mask,V_obs,A_obs,A_dir_obs, V_tr,A_tr,A_dir_tr = batch\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        #Forward\n",
        "        #V_obs = batch,seq,node,feat\n",
        "        #V_obs_tmp = batch,feat,seq,node\n",
        "        V_obs_tmp =V_obs.permute(0,3,1,2)\n",
        "\n",
        "        V_pred,_,_ = model(V_obs_tmp,A_obs.squeeze(), A_dir_obs.squeeze())\n",
        "\n",
        "        V_pred = V_pred.permute(0,2,3,1)\n",
        "\n",
        "\n",
        "\n",
        "        V_tr = V_tr.squeeze()\n",
        "        A_tr = A_tr.squeeze()\n",
        "        A_dir_tr = A_dir_tr.squeeze()\n",
        "        V_pred = V_pred.squeeze()\n",
        "\n",
        "        if batch_count%args.batch_size !=0 and cnt != turn_point :\n",
        "            l = graph_loss(V_pred,V_tr)\n",
        "            if is_fst_loss :\n",
        "                loss = l\n",
        "                is_fst_loss = False\n",
        "            else:\n",
        "                loss += l\n",
        "\n",
        "        else:\n",
        "            loss = loss/args.batch_size\n",
        "            is_fst_loss = True\n",
        "            loss.backward()\n",
        "\n",
        "            if args.clip_grad is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(),args.clip_grad)\n",
        "\n",
        "\n",
        "            optimizer.step()\n",
        "            #Metrics\n",
        "            loss_batch += loss.item()\n",
        "            print('TRAIN:','\\t Epoch:', epoch,'\\t Loss:',loss_batch/batch_count)\n",
        "\n",
        "    metrics['train_loss'].append(loss_batch/batch_count)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def vald(epoch):\n",
        "    global metrics,loader_val,constant_metrics\n",
        "    model.eval()\n",
        "    loss_batch = 0\n",
        "    batch_count = 0\n",
        "    is_fst_loss = True\n",
        "    loader_len = len(loader_val)\n",
        "    turn_point =int(loader_len/args.batch_size)*args.batch_size+ loader_len%args.batch_size -1\n",
        "\n",
        "    for cnt,batch in enumerate(loader_val):\n",
        "        batch_count+=1\n",
        "\n",
        "        #Get data\n",
        "        batch = [tensor for tensor in batch]\n",
        "        obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\\\n",
        "         loss_mask,V_obs,A_obs,A_dir_obs, V_tr,A_tr,A_dir_tr = batch\n",
        "\n",
        "\n",
        "        V_obs_tmp =V_obs.permute(0,3,1,2)\n",
        "\n",
        "        V_pred,_,_ = model(V_obs_tmp,A_obs.squeeze(), A_dir_obs.squeeze())\n",
        "\n",
        "        V_pred = V_pred.permute(0,2,3,1)\n",
        "\n",
        "        V_tr = V_tr.squeeze()\n",
        "        A_tr = A_tr.squeeze()\n",
        "        A_dir_tr = A_dir_tr.squeeze()\n",
        "        V_pred = V_pred.squeeze()\n",
        "\n",
        "        if batch_count%args.batch_size !=0 and cnt != turn_point :\n",
        "            l = graph_loss(V_pred,V_tr)\n",
        "            if is_fst_loss :\n",
        "                loss = l\n",
        "                is_fst_loss = False\n",
        "            else:\n",
        "                loss += l\n",
        "\n",
        "        else:\n",
        "            loss = loss/args.batch_size\n",
        "            is_fst_loss = True\n",
        "            #Metrics\n",
        "            loss_batch += loss.item()\n",
        "            print('VALD:','\\t Epoch:', epoch,'\\t Loss:',loss_batch/batch_count)\n",
        "\n",
        "    metrics['val_loss'].append(loss_batch/batch_count)\n",
        "\n",
        "    if  metrics['val_loss'][-1]< constant_metrics['min_val_loss']:\n",
        "        constant_metrics['min_val_loss'] =  metrics['val_loss'][-1]\n",
        "        constant_metrics['min_val_epoch'] = epoch\n",
        "        torch.save(model.state_dict(),checkpoint_dir+'val_best.pth')  # OK\n",
        "        check_test_performance()\n",
        "\n",
        "print('Training started ...')\n",
        "for epoch in range(args.num_epochs):\n",
        "    train(epoch)\n",
        "    vald(epoch)\n",
        "    if args.use_lrschd:\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "    print('*'*30)\n",
        "    print('Epoch:',args.tag,\":\", epoch)\n",
        "    for k,v in metrics.items():\n",
        "        if len(v)>0:\n",
        "            print(k,v[-1])\n",
        "\n",
        "\n",
        "    print(constant_metrics)\n",
        "    print('*'*30)\n",
        "\n",
        "    with open(checkpoint_dir+'metrics.pkl', 'wb') as fp:\n",
        "        pickle.dump(metrics, fp)\n",
        "\n",
        "    with open(checkpoint_dir+'constant_metrics.pkl', 'wb') as fp:\n",
        "        pickle.dump(constant_metrics, fp)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-03T20:26:44.963492Z",
          "iopub.execute_input": "2024-06-03T20:26:44.963848Z"
        },
        "trusted": true,
        "id": "YQ7BFbg3b0cq",
        "outputId": "9dd501fe-4b64-4e65-c1b0-4712ed2b5669"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Data and model loaded\nCheckpoint dir: ./checkpoint/social-tag/\nTraining started ...\nTRAIN: \t Epoch: 0 \t Loss: 0.016207104548811913\nTRAIN: \t Epoch: 0 \t Loss: 0.015882850624620914\nTRAIN: \t Epoch: 0 \t Loss: 0.015689566421012085\nTRAIN: \t Epoch: 0 \t Loss: 0.015459113288670778\nTRAIN: \t Epoch: 0 \t Loss: 0.015237803757190704\nTRAIN: \t Epoch: 0 \t Loss: 0.015015211887657642\nTRAIN: \t Epoch: 0 \t Loss: 0.014812008743839604\nTRAIN: \t Epoch: 0 \t Loss: 0.014622995280660689\nTRAIN: \t Epoch: 0 \t Loss: 0.01444061566144228\nTRAIN: \t Epoch: 0 \t Loss: 0.014245782885700465\nTRAIN: \t Epoch: 0 \t Loss: 0.014046812768686901\nTRAIN: \t Epoch: 0 \t Loss: 0.013863949881245693\nTRAIN: \t Epoch: 0 \t Loss: 0.01367377618757578\nTRAIN: \t Epoch: 0 \t Loss: 0.01348486150215779\nTRAIN: \t Epoch: 0 \t Loss: 0.013300742457310359\nTRAIN: \t Epoch: 0 \t Loss: 0.013114072848111391\nTRAIN: \t Epoch: 0 \t Loss: 0.013066317591823366\nVALD: \t Epoch: 0 \t Loss: 0.010786443948745728\nVALD: \t Epoch: 0 \t Loss: 0.012944892980158329\nVALD: \t Epoch: 0 \t Loss: 0.012138931701580683\nVALD: \t Epoch: 0 \t Loss: 0.01150006172247231\nVALD: \t Epoch: 0 \t Loss: 0.01148518037121251\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [18:03<00:00,  1.14s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 1.1845755289836106  FDE: 1.1428070892911715\n**************************************************\n******************************\nEpoch: social-tag : 0\ntrain_loss 0.013066317591823366\nval_loss 0.01148518037121251\n{'min_val_epoch': 0, 'min_val_loss': 0.01148518037121251}\n******************************\nTRAIN: \t Epoch: 1 \t Loss: 0.009672910906374454\nTRAIN: \t Epoch: 1 \t Loss: 0.009489190764725208\nTRAIN: \t Epoch: 1 \t Loss: 0.009329176507890224\nTRAIN: \t Epoch: 1 \t Loss: 0.009113092673942447\nTRAIN: \t Epoch: 1 \t Loss: 0.008886980265378952\nTRAIN: \t Epoch: 1 \t Loss: 0.008760280596713224\nTRAIN: \t Epoch: 1 \t Loss: 0.008615195817713226\nTRAIN: \t Epoch: 1 \t Loss: 0.008419841702561826\nTRAIN: \t Epoch: 1 \t Loss: 0.008267498161229823\nTRAIN: \t Epoch: 1 \t Loss: 0.008108079293742776\nTRAIN: \t Epoch: 1 \t Loss: 0.007937206971374426\nTRAIN: \t Epoch: 1 \t Loss: 0.007883728404218951\nTRAIN: \t Epoch: 1 \t Loss: 0.007777526867217743\nTRAIN: \t Epoch: 1 \t Loss: 0.007643613631704024\nTRAIN: \t Epoch: 1 \t Loss: 0.0074776688901086645\nTRAIN: \t Epoch: 1 \t Loss: 0.007305795210413635\nTRAIN: \t Epoch: 1 \t Loss: 0.007272285748423869\nVALD: \t Epoch: 1 \t Loss: 0.027523603290319443\nVALD: \t Epoch: 1 \t Loss: 0.04182785749435425\nVALD: \t Epoch: 1 \t Loss: 0.031813885706166424\nVALD: \t Epoch: 1 \t Loss: 0.0274769295938313\nVALD: \t Epoch: 1 \t Loss: 0.02702769642730929\n******************************\nEpoch: social-tag : 1\ntrain_loss 0.007272285748423869\nval_loss 0.02702769642730929\n{'min_val_epoch': 0, 'min_val_loss': 0.01148518037121251}\n******************************\nTRAIN: \t Epoch: 2 \t Loss: 0.0051812403835356236\nTRAIN: \t Epoch: 2 \t Loss: 0.0050084455870091915\nTRAIN: \t Epoch: 2 \t Loss: 0.004891429872562488\nTRAIN: \t Epoch: 2 \t Loss: 0.004678540281020105\nTRAIN: \t Epoch: 2 \t Loss: 0.004667668789625168\nTRAIN: \t Epoch: 2 \t Loss: 0.004734574351459742\nTRAIN: \t Epoch: 2 \t Loss: 0.004712492493646485\nTRAIN: \t Epoch: 2 \t Loss: 0.0046442768652923405\nTRAIN: \t Epoch: 2 \t Loss: 0.004537820712559753\nTRAIN: \t Epoch: 2 \t Loss: 0.004418156249448657\nTRAIN: \t Epoch: 2 \t Loss: 0.004319716668264432\nTRAIN: \t Epoch: 2 \t Loss: 0.004310270228112738\nTRAIN: \t Epoch: 2 \t Loss: 0.004370909542418444\nTRAIN: \t Epoch: 2 \t Loss: 0.004368861139352832\nTRAIN: \t Epoch: 2 \t Loss: 0.004271080205217004\nTRAIN: \t Epoch: 2 \t Loss: 0.004122815320442896\nTRAIN: \t Epoch: 2 \t Loss: 0.004089475982608937\nVALD: \t Epoch: 2 \t Loss: 0.02819805219769478\nVALD: \t Epoch: 2 \t Loss: 0.047819433733820915\nVALD: \t Epoch: 2 \t Loss: 0.03519678767770529\nVALD: \t Epoch: 2 \t Loss: 0.030102492542937398\nVALD: \t Epoch: 2 \t Loss: 0.030141396455045016\n******************************\nEpoch: social-tag : 2\ntrain_loss 0.004089475982608937\nval_loss 0.030141396455045016\n{'min_val_epoch': 0, 'min_val_loss': 0.01148518037121251}\n******************************\nTRAIN: \t Epoch: 3 \t Loss: 0.0024753131438046694\nTRAIN: \t Epoch: 3 \t Loss: 0.0029816789319738746\nTRAIN: \t Epoch: 3 \t Loss: 0.0034583911765366793\nTRAIN: \t Epoch: 3 \t Loss: 0.0033973276731558144\nTRAIN: \t Epoch: 3 \t Loss: 0.0031590834259986877\nTRAIN: \t Epoch: 3 \t Loss: 0.002933735571180781\nTRAIN: \t Epoch: 3 \t Loss: 0.0027714419910418136\nTRAIN: \t Epoch: 3 \t Loss: 0.0025774514506338164\nTRAIN: \t Epoch: 3 \t Loss: 0.002440596452086336\nTRAIN: \t Epoch: 3 \t Loss: 0.002971489995252341\nTRAIN: \t Epoch: 3 \t Loss: 0.00329154004893181\nTRAIN: \t Epoch: 3 \t Loss: 0.0034726546437013894\nTRAIN: \t Epoch: 3 \t Loss: 0.0035645242762536956\nTRAIN: \t Epoch: 3 \t Loss: 0.003532134470463331\nTRAIN: \t Epoch: 3 \t Loss: 0.0034478032573436695\nTRAIN: \t Epoch: 3 \t Loss: 0.003306778467958793\nTRAIN: \t Epoch: 3 \t Loss: 0.003295992474163199\nVALD: \t Epoch: 3 \t Loss: 0.003924557473510504\nVALD: \t Epoch: 3 \t Loss: 0.009377948706969619\nVALD: \t Epoch: 3 \t Loss: 0.007892552142341932\nVALD: \t Epoch: 3 \t Loss: 0.006100268947193399\nVALD: \t Epoch: 3 \t Loss: 0.006980255218047016\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [18:02<00:00,  1.14s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.7315192762332513  FDE: 0.8045620603143804\n**************************************************\n******************************\nEpoch: social-tag : 3\ntrain_loss 0.003295992474163199\nval_loss 0.006980255218047016\n{'min_val_epoch': 3, 'min_val_loss': 0.006980255218047016}\n******************************\nTRAIN: \t Epoch: 4 \t Loss: 0.0012528012739494443\nTRAIN: \t Epoch: 4 \t Loss: 0.0009936652786564082\nTRAIN: \t Epoch: 4 \t Loss: 0.0009392030769959092\nTRAIN: \t Epoch: 4 \t Loss: 0.001986642455449328\nTRAIN: \t Epoch: 4 \t Loss: 0.0027210355503484605\nTRAIN: \t Epoch: 4 \t Loss: 0.003093017633849134\nTRAIN: \t Epoch: 4 \t Loss: 0.0031604060204699636\nTRAIN: \t Epoch: 4 \t Loss: 0.0030944011377869174\nTRAIN: \t Epoch: 4 \t Loss: 0.0029543694238074953\nTRAIN: \t Epoch: 4 \t Loss: 0.002741876739310101\nTRAIN: \t Epoch: 4 \t Loss: 0.00249430341186367\nTRAIN: \t Epoch: 4 \t Loss: 0.0022957879302036113\nTRAIN: \t Epoch: 4 \t Loss: 0.002117692102659091\nTRAIN: \t Epoch: 4 \t Loss: 0.0021855592197295793\nTRAIN: \t Epoch: 4 \t Loss: 0.0021370342732552673\nTRAIN: \t Epoch: 4 \t Loss: 0.002022705091235366\nTRAIN: \t Epoch: 4 \t Loss: 0.0019783251204434603\nVALD: \t Epoch: 4 \t Loss: 0.004486795049160719\nVALD: \t Epoch: 4 \t Loss: 0.005427774274721742\nVALD: \t Epoch: 4 \t Loss: 0.004831157314280669\nVALD: \t Epoch: 4 \t Loss: 0.003521457540045958\nVALD: \t Epoch: 4 \t Loss: 0.0036029925113016704\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [19:02<00:00,  1.21s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.7234454637197821  FDE: 0.814016846302669\n**************************************************\n******************************\nEpoch: social-tag : 4\ntrain_loss 0.0019783251204434603\nval_loss 0.0036029925113016704\n{'min_val_epoch': 4, 'min_val_loss': 0.0036029925113016704}\n******************************\nTRAIN: \t Epoch: 5 \t Loss: -5.286583473207429e-05\nTRAIN: \t Epoch: 5 \t Loss: -0.000680947912769625\nTRAIN: \t Epoch: 5 \t Loss: -0.000495780960288054\nTRAIN: \t Epoch: 5 \t Loss: 0.0002933898922492517\nTRAIN: \t Epoch: 5 \t Loss: 0.00099052502628183\nTRAIN: \t Epoch: 5 \t Loss: 0.0010764788397257992\nTRAIN: \t Epoch: 5 \t Loss: 0.001018880341559582\nTRAIN: \t Epoch: 5 \t Loss: 0.0007233216811073362\nTRAIN: \t Epoch: 5 \t Loss: 0.0005784599464580727\nTRAIN: \t Epoch: 5 \t Loss: 0.0004249895158864092\nTRAIN: \t Epoch: 5 \t Loss: 0.0005145364127449945\nTRAIN: \t Epoch: 5 \t Loss: 0.0008876818022448182\nTRAIN: \t Epoch: 5 \t Loss: 0.0010056484153700205\nTRAIN: \t Epoch: 5 \t Loss: 0.0010042991192936565\nTRAIN: \t Epoch: 5 \t Loss: 0.0009201086703493881\nTRAIN: \t Epoch: 5 \t Loss: 0.0008301671364279173\nTRAIN: \t Epoch: 5 \t Loss: 0.0008253172647408954\nVALD: \t Epoch: 5 \t Loss: 0.007493333425372839\nVALD: \t Epoch: 5 \t Loss: 0.01154150697402656\nVALD: \t Epoch: 5 \t Loss: 0.009495941922068596\nVALD: \t Epoch: 5 \t Loss: 0.006715482362778857\nVALD: \t Epoch: 5 \t Loss: 0.006990394530431279\n******************************\nEpoch: social-tag : 5\ntrain_loss 0.0008253172647408954\nval_loss 0.006990394530431279\n{'min_val_epoch': 4, 'min_val_loss': 0.0036029925113016704}\n******************************\nTRAIN: \t Epoch: 6 \t Loss: -0.001140281674452126\nTRAIN: \t Epoch: 6 \t Loss: -0.0009399847767781466\nTRAIN: \t Epoch: 6 \t Loss: -0.0012541586960045\nTRAIN: \t Epoch: 6 \t Loss: -0.0015285592380678281\nTRAIN: \t Epoch: 6 \t Loss: -0.0011667766899336129\nTRAIN: \t Epoch: 6 \t Loss: -0.0008276772714452818\nTRAIN: \t Epoch: 6 \t Loss: -0.00046697423178037364\nTRAIN: \t Epoch: 6 \t Loss: -0.00047299456855398603\nTRAIN: \t Epoch: 6 \t Loss: -0.0005543597281858739\nTRAIN: \t Epoch: 6 \t Loss: -0.0007014470204012469\nTRAIN: \t Epoch: 6 \t Loss: -0.0007777928126002239\nTRAIN: \t Epoch: 6 \t Loss: -0.00047804026447314146\nTRAIN: \t Epoch: 6 \t Loss: -0.00020874479042294508\nTRAIN: \t Epoch: 6 \t Loss: -0.00013295977883639613\nTRAIN: \t Epoch: 6 \t Loss: -0.00017275807331316174\nTRAIN: \t Epoch: 6 \t Loss: -0.00027398369456932414\nTRAIN: \t Epoch: 6 \t Loss: -0.0002888553077803641\nVALD: \t Epoch: 6 \t Loss: -0.00045113833039067686\nVALD: \t Epoch: 6 \t Loss: 0.006046081849490292\nVALD: \t Epoch: 6 \t Loss: 0.004511993543322508\nVALD: \t Epoch: 6 \t Loss: 0.0027387348891352303\nVALD: \t Epoch: 6 \t Loss: 0.0026365570803085028\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [17:56<00:00,  1.14s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.6350231673240279  FDE: 0.7494710037343442\n**************************************************\n******************************\nEpoch: social-tag : 6\ntrain_loss -0.0002888553077803641\nval_loss 0.0026365570803085028\n{'min_val_epoch': 6, 'min_val_loss': 0.0026365570803085028}\n******************************\nTRAIN: \t Epoch: 7 \t Loss: -0.0026264607440680265\nTRAIN: \t Epoch: 7 \t Loss: -0.002222678973339498\nTRAIN: \t Epoch: 7 \t Loss: -0.0002093696966767311\nTRAIN: \t Epoch: 7 \t Loss: 0.00102871039416641\nTRAIN: \t Epoch: 7 \t Loss: 0.0016725249588489532\nTRAIN: \t Epoch: 7 \t Loss: 0.0019312032964080572\nTRAIN: \t Epoch: 7 \t Loss: 0.0019700956264776842\nTRAIN: \t Epoch: 7 \t Loss: 0.0018847527826437727\nTRAIN: \t Epoch: 7 \t Loss: 0.0016976319877560148\nTRAIN: \t Epoch: 7 \t Loss: 0.0014996276571764612\nTRAIN: \t Epoch: 7 \t Loss: 0.0012876212382583287\nTRAIN: \t Epoch: 7 \t Loss: 0.0010262720206810627\nTRAIN: \t Epoch: 7 \t Loss: 0.0007789513452175575\nTRAIN: \t Epoch: 7 \t Loss: 0.0005503388352475927\nTRAIN: \t Epoch: 7 \t Loss: 0.00036901571147609504\nTRAIN: \t Epoch: 7 \t Loss: 0.000375756001631089\nTRAIN: \t Epoch: 7 \t Loss: 0.00040663253096056125\nVALD: \t Epoch: 7 \t Loss: 0.003797026351094246\nVALD: \t Epoch: 7 \t Loss: 0.008078558370471\nVALD: \t Epoch: 7 \t Loss: 0.0062937236701448756\nVALD: \t Epoch: 7 \t Loss: 0.004500551178352907\nVALD: \t Epoch: 7 \t Loss: 0.004538008683132675\n******************************\nEpoch: social-tag : 7\ntrain_loss 0.00040663253096056125\nval_loss 0.004538008683132675\n{'min_val_epoch': 6, 'min_val_loss': 0.0026365570803085028}\n******************************\nTRAIN: \t Epoch: 8 \t Loss: 0.00014903544797562063\nTRAIN: \t Epoch: 8 \t Loss: -0.0007532400341005996\nTRAIN: \t Epoch: 8 \t Loss: -0.0011309668285927426\nTRAIN: \t Epoch: 8 \t Loss: -0.001477888938097749\nTRAIN: \t Epoch: 8 \t Loss: -0.001645739219384268\nTRAIN: \t Epoch: 8 \t Loss: -0.001803145224888188\nTRAIN: \t Epoch: 8 \t Loss: -0.00139608808344097\nTRAIN: \t Epoch: 8 \t Loss: -0.0009020752804644872\nTRAIN: \t Epoch: 8 \t Loss: -0.0007688208263263934\nTRAIN: \t Epoch: 8 \t Loss: -0.0008381378778722137\nTRAIN: \t Epoch: 8 \t Loss: -0.0010180632446215234\nTRAIN: \t Epoch: 8 \t Loss: -0.001201995449567524\nTRAIN: \t Epoch: 8 \t Loss: -0.0013898252822960226\nTRAIN: \t Epoch: 8 \t Loss: -0.001446021899547694\nTRAIN: \t Epoch: 8 \t Loss: -0.001346867762185866\nTRAIN: \t Epoch: 8 \t Loss: -0.0010537127507177502\nTRAIN: \t Epoch: 8 \t Loss: -0.001033811706391043\nVALD: \t Epoch: 8 \t Loss: 0.0007888010004535317\nVALD: \t Epoch: 8 \t Loss: 0.003406196425203234\nVALD: \t Epoch: 8 \t Loss: 0.002784224498706559\nVALD: \t Epoch: 8 \t Loss: 0.0019306860049255192\nVALD: \t Epoch: 8 \t Loss: 0.0018157498419003667\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [17:52<00:00,  1.13s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.674158422982008  FDE: 0.7496676152492304\n**************************************************\n******************************\nEpoch: social-tag : 8\ntrain_loss -0.001033811706391043\nval_loss 0.0018157498419003667\n{'min_val_epoch': 8, 'min_val_loss': 0.0018157498419003667}\n******************************\nTRAIN: \t Epoch: 9 \t Loss: 2.212492108810693e-05\nTRAIN: \t Epoch: 9 \t Loss: -0.0005998527267365716\nTRAIN: \t Epoch: 9 \t Loss: -0.0013915614448099707\nTRAIN: \t Epoch: 9 \t Loss: -0.002077304681733949\nTRAIN: \t Epoch: 9 \t Loss: -0.0021770267136162146\nTRAIN: \t Epoch: 9 \t Loss: -0.0023704115956206806\nTRAIN: \t Epoch: 9 \t Loss: -0.002290141592051701\nTRAIN: \t Epoch: 9 \t Loss: -0.0022233555118873483\nTRAIN: \t Epoch: 9 \t Loss: -0.002171108180644094\nTRAIN: \t Epoch: 9 \t Loss: -0.002032434339344036\nTRAIN: \t Epoch: 9 \t Loss: -0.0020725738974182273\nTRAIN: \t Epoch: 9 \t Loss: -0.0021959950912181134\nTRAIN: \t Epoch: 9 \t Loss: -0.002183190532377921\nTRAIN: \t Epoch: 9 \t Loss: -0.002033658142733787\nTRAIN: \t Epoch: 9 \t Loss: -0.0019021477664258176\nTRAIN: \t Epoch: 9 \t Loss: -0.001861127169604515\nTRAIN: \t Epoch: 9 \t Loss: -0.0018841345148046208\nVALD: \t Epoch: 9 \t Loss: 0.0012021316215395927\nVALD: \t Epoch: 9 \t Loss: 0.006144244689494371\nVALD: \t Epoch: 9 \t Loss: 0.004688809858635068\nVALD: \t Epoch: 9 \t Loss: 0.0025444841594435275\nVALD: \t Epoch: 9 \t Loss: 0.002562097228079472\n******************************\nEpoch: social-tag : 9\ntrain_loss -0.0018841345148046208\nval_loss 0.002562097228079472\n{'min_val_epoch': 8, 'min_val_loss': 0.0018157498419003667}\n******************************\nTRAIN: \t Epoch: 10 \t Loss: -0.002979674842208624\nTRAIN: \t Epoch: 10 \t Loss: -0.003606035839766264\nTRAIN: \t Epoch: 10 \t Loss: -0.003843227867037058\nTRAIN: \t Epoch: 10 \t Loss: -0.0035705206100828946\nTRAIN: \t Epoch: 10 \t Loss: -0.002986187161877751\nTRAIN: \t Epoch: 10 \t Loss: -0.002134486062762638\nTRAIN: \t Epoch: 10 \t Loss: -0.0019954435161447953\nTRAIN: \t Epoch: 10 \t Loss: -0.0019681339617818594\nTRAIN: \t Epoch: 10 \t Loss: -0.002113667911746436\nTRAIN: \t Epoch: 10 \t Loss: -0.002203709608875215\nTRAIN: \t Epoch: 10 \t Loss: -0.0022961910263719883\nTRAIN: \t Epoch: 10 \t Loss: -0.002480032911989838\nTRAIN: \t Epoch: 10 \t Loss: -0.002571246998671156\nTRAIN: \t Epoch: 10 \t Loss: -0.0025534576935959713\nTRAIN: \t Epoch: 10 \t Loss: -0.0022970490079994004\nTRAIN: \t Epoch: 10 \t Loss: -0.0021864996815565974\nTRAIN: \t Epoch: 10 \t Loss: -0.0021975571056379287\nVALD: \t Epoch: 10 \t Loss: -0.002051701070740819\nVALD: \t Epoch: 10 \t Loss: 0.00310428102966398\nVALD: \t Epoch: 10 \t Loss: 0.001632392134827872\nVALD: \t Epoch: 10 \t Loss: 0.000527225638506934\nVALD: \t Epoch: 10 \t Loss: 0.00036530141841690497\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [17:50<00:00,  1.13s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.6535959887255023  FDE: 0.7472705230988342\n**************************************************\n******************************\nEpoch: social-tag : 10\ntrain_loss -0.0021975571056379287\nval_loss 0.00036530141841690497\n{'min_val_epoch': 10, 'min_val_loss': 0.00036530141841690497}\n******************************\nTRAIN: \t Epoch: 11 \t Loss: -0.0023590335622429848\nTRAIN: \t Epoch: 11 \t Loss: -0.0029751568799838424\nTRAIN: \t Epoch: 11 \t Loss: -0.003366777285312613\nTRAIN: \t Epoch: 11 \t Loss: -0.0036130998632870615\nTRAIN: \t Epoch: 11 \t Loss: -0.0028272931929677727\nTRAIN: \t Epoch: 11 \t Loss: -0.0020474418609713516\nTRAIN: \t Epoch: 11 \t Loss: -0.0018281416185865445\nTRAIN: \t Epoch: 11 \t Loss: -0.0018635225787875243\nTRAIN: \t Epoch: 11 \t Loss: -0.001999078945825911\nTRAIN: \t Epoch: 11 \t Loss: -0.002162430860335007\nTRAIN: \t Epoch: 11 \t Loss: -0.0024019179241308434\nTRAIN: \t Epoch: 11 \t Loss: -0.0025642395145647847\nTRAIN: \t Epoch: 11 \t Loss: -0.0025151646830356466\nTRAIN: \t Epoch: 11 \t Loss: -0.002255982523950349\nTRAIN: \t Epoch: 11 \t Loss: -0.0022040464721309644\nTRAIN: \t Epoch: 11 \t Loss: -0.002250839981570607\nTRAIN: \t Epoch: 11 \t Loss: -0.0022402589006604258\nVALD: \t Epoch: 11 \t Loss: -0.0024561178870499134\nVALD: \t Epoch: 11 \t Loss: 0.004563475260511041\nVALD: \t Epoch: 11 \t Loss: 0.002733266078090916\nVALD: \t Epoch: 11 \t Loss: 0.0008478281815769151\nVALD: \t Epoch: 11 \t Loss: 0.0007736248719804692\n******************************\nEpoch: social-tag : 11\ntrain_loss -0.0022402589006604258\nval_loss 0.0007736248719804692\n{'min_val_epoch': 10, 'min_val_loss': 0.00036530141841690497}\n******************************\nTRAIN: \t Epoch: 12 \t Loss: -0.004465781152248383\nTRAIN: \t Epoch: 12 \t Loss: -0.004675042582675815\nTRAIN: \t Epoch: 12 \t Loss: -0.0048820325173437595\nTRAIN: \t Epoch: 12 \t Loss: -0.0044725152547471225\nTRAIN: \t Epoch: 12 \t Loss: -0.004077471280470491\nTRAIN: \t Epoch: 12 \t Loss: -0.0038150192704051733\nTRAIN: \t Epoch: 12 \t Loss: -0.003642380636717592\nTRAIN: \t Epoch: 12 \t Loss: -0.003716571896802634\nTRAIN: \t Epoch: 12 \t Loss: -0.0037789657298061582\nTRAIN: \t Epoch: 12 \t Loss: -0.0038558946922421455\nTRAIN: \t Epoch: 12 \t Loss: -0.003758497726680203\nTRAIN: \t Epoch: 12 \t Loss: -0.0033351643942296505\nTRAIN: \t Epoch: 12 \t Loss: -0.003170813541286267\nTRAIN: \t Epoch: 12 \t Loss: -0.0031354868219101\nTRAIN: \t Epoch: 12 \t Loss: -0.0032317375609030325\nTRAIN: \t Epoch: 12 \t Loss: -0.003288032705313526\nTRAIN: \t Epoch: 12 \t Loss: -0.0033142679300955952\nVALD: \t Epoch: 12 \t Loss: 0.001710765645839274\nVALD: \t Epoch: 12 \t Loss: 0.011075897433329374\nVALD: \t Epoch: 12 \t Loss: 0.008445775330377122\nVALD: \t Epoch: 12 \t Loss: 0.005352226580725983\nVALD: \t Epoch: 12 \t Loss: 0.005921548408157421\n******************************\nEpoch: social-tag : 12\ntrain_loss -0.0033142679300955952\nval_loss 0.005921548408157421\n{'min_val_epoch': 10, 'min_val_loss': 0.00036530141841690497}\n******************************\nTRAIN: \t Epoch: 13 \t Loss: -0.005400277674198151\nTRAIN: \t Epoch: 13 \t Loss: -0.005073919426649809\nTRAIN: \t Epoch: 13 \t Loss: -0.00477238092571497\nTRAIN: \t Epoch: 13 \t Loss: -0.004337439138907939\nTRAIN: \t Epoch: 13 \t Loss: -0.003391894302330911\nTRAIN: \t Epoch: 13 \t Loss: -0.0032105263671837747\nTRAIN: \t Epoch: 13 \t Loss: -0.0031701000573645744\nTRAIN: \t Epoch: 13 \t Loss: -0.0033206559164682403\nTRAIN: \t Epoch: 13 \t Loss: -0.0034628674620762467\nTRAIN: \t Epoch: 13 \t Loss: -0.0036204123054631053\nTRAIN: \t Epoch: 13 \t Loss: -0.0037669258467345076\nTRAIN: \t Epoch: 13 \t Loss: -0.00378944842183652\nTRAIN: \t Epoch: 13 \t Loss: -0.00338809579037703\nTRAIN: \t Epoch: 13 \t Loss: -0.0031340139789140914\nTRAIN: \t Epoch: 13 \t Loss: -0.0030528635970161607\nTRAIN: \t Epoch: 13 \t Loss: -0.0030426099201577017\nTRAIN: \t Epoch: 13 \t Loss: -0.0030556591909543856\nVALD: \t Epoch: 13 \t Loss: -0.003744068555533886\nVALD: \t Epoch: 13 \t Loss: 0.003336207941174507\nVALD: \t Epoch: 13 \t Loss: 0.0016047736474623282\nVALD: \t Epoch: 13 \t Loss: -5.4664735216647387e-05\nVALD: \t Epoch: 13 \t Loss: -9.525878319762787e-05\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [18:03<00:00,  1.14s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.6259027431470516  FDE: 0.802638712192935\n**************************************************\n******************************\nEpoch: social-tag : 13\ntrain_loss -0.0030556591909543856\nval_loss -9.525878319762787e-05\n{'min_val_epoch': 13, 'min_val_loss': -9.525878319762787e-05}\n******************************\nTRAIN: \t Epoch: 14 \t Loss: -0.005024553742259741\nTRAIN: \t Epoch: 14 \t Loss: -0.005119300447404385\nTRAIN: \t Epoch: 14 \t Loss: -0.005122767295688391\nTRAIN: \t Epoch: 14 \t Loss: -0.004533176717814058\nTRAIN: \t Epoch: 14 \t Loss: -0.0032698204973712563\nTRAIN: \t Epoch: 14 \t Loss: -0.0030098120332695544\nTRAIN: \t Epoch: 14 \t Loss: -0.0030234524082126363\nTRAIN: \t Epoch: 14 \t Loss: -0.0032222343288594857\nTRAIN: \t Epoch: 14 \t Loss: -0.003390563561374115\nTRAIN: \t Epoch: 14 \t Loss: -0.00358370152534917\nTRAIN: \t Epoch: 14 \t Loss: -0.003751391513188454\nTRAIN: \t Epoch: 14 \t Loss: -0.003903267914817358\nTRAIN: \t Epoch: 14 \t Loss: -0.0035511483886064244\nTRAIN: \t Epoch: 14 \t Loss: -0.0032536656653974205\nTRAIN: \t Epoch: 14 \t Loss: -0.0030963203753344715\nTRAIN: \t Epoch: 14 \t Loss: -0.003054769116715761\nTRAIN: \t Epoch: 14 \t Loss: -0.003065819584680201\nVALD: \t Epoch: 14 \t Loss: -0.0016559462528675795\nVALD: \t Epoch: 14 \t Loss: 0.005629791528917849\nVALD: \t Epoch: 14 \t Loss: 0.0030897921727349362\nVALD: \t Epoch: 14 \t Loss: 0.0014841241645626724\nVALD: \t Epoch: 14 \t Loss: 0.0013182391887003521\n******************************\nEpoch: social-tag : 14\ntrain_loss -0.003065819584680201\nval_loss 0.0013182391887003521\n{'min_val_epoch': 13, 'min_val_loss': -9.525878319762787e-05}\n******************************\nTRAIN: \t Epoch: 15 \t Loss: -0.0037799084093421698\nTRAIN: \t Epoch: 15 \t Loss: -0.004129402455873787\nTRAIN: \t Epoch: 15 \t Loss: -0.004633192050581177\nTRAIN: \t Epoch: 15 \t Loss: -0.004819807654712349\nTRAIN: \t Epoch: 15 \t Loss: -0.005125891463831067\nTRAIN: \t Epoch: 15 \t Loss: -0.00482700124848634\nTRAIN: \t Epoch: 15 \t Loss: -0.004574711234974009\nTRAIN: \t Epoch: 15 \t Loss: -0.004252700717188418\nTRAIN: \t Epoch: 15 \t Loss: -0.0042302354445887935\nTRAIN: \t Epoch: 15 \t Loss: -0.004303082032129169\nTRAIN: \t Epoch: 15 \t Loss: -0.004390769765119661\nTRAIN: \t Epoch: 15 \t Loss: -0.004459924801873664\nTRAIN: \t Epoch: 15 \t Loss: -0.004463006563198108\nTRAIN: \t Epoch: 15 \t Loss: -0.004092285035377634\nTRAIN: \t Epoch: 15 \t Loss: -0.003771584298616896\nTRAIN: \t Epoch: 15 \t Loss: -0.0036855685357295442\nTRAIN: \t Epoch: 15 \t Loss: -0.003673923727634555\nVALD: \t Epoch: 15 \t Loss: -0.004802432376891375\nVALD: \t Epoch: 15 \t Loss: -0.0015700411750003695\nVALD: \t Epoch: 15 \t Loss: -0.002061840302000443\nVALD: \t Epoch: 15 \t Loss: -0.0027177472366020083\nVALD: \t Epoch: 15 \t Loss: -0.0028133370685127545\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [17:56<00:00,  1.14s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.5975233339279883  FDE: 0.7006429071961441\n**************************************************\n******************************\nEpoch: social-tag : 15\ntrain_loss -0.003673923727634555\nval_loss -0.0028133370685127545\n{'min_val_epoch': 15, 'min_val_loss': -0.0028133370685127545}\n******************************\nTRAIN: \t Epoch: 16 \t Loss: -0.0034992005676031113\nTRAIN: \t Epoch: 16 \t Loss: -0.004038421669974923\nTRAIN: \t Epoch: 16 \t Loss: -0.0045130459281305475\nTRAIN: \t Epoch: 16 \t Loss: -0.0049730666214600205\nTRAIN: \t Epoch: 16 \t Loss: -0.005005284864455462\nTRAIN: \t Epoch: 16 \t Loss: -0.004934340715408325\nTRAIN: \t Epoch: 16 \t Loss: -0.004743756027892232\nTRAIN: \t Epoch: 16 \t Loss: -0.004242391987645533\nTRAIN: \t Epoch: 16 \t Loss: -0.004087541530477918\nTRAIN: \t Epoch: 16 \t Loss: -0.0041275968018453565\nTRAIN: \t Epoch: 16 \t Loss: -0.004268419860057871\nTRAIN: \t Epoch: 16 \t Loss: -0.004395253388793208\nTRAIN: \t Epoch: 16 \t Loss: -0.004556241924337183\nTRAIN: \t Epoch: 16 \t Loss: -0.004659493798888954\nTRAIN: \t Epoch: 16 \t Loss: -0.004555202178501834\nTRAIN: \t Epoch: 16 \t Loss: -0.00420598098935443\nTRAIN: \t Epoch: 16 \t Loss: -0.004174307162778341\nVALD: \t Epoch: 16 \t Loss: -0.0017883701948449016\nVALD: \t Epoch: 16 \t Loss: 0.0028518804465420544\nVALD: \t Epoch: 16 \t Loss: 0.0014224180486053228\nVALD: \t Epoch: 16 \t Loss: 0.00034588604466989636\nVALD: \t Epoch: 16 \t Loss: 0.00020654850973273224\n******************************\nEpoch: social-tag : 16\ntrain_loss -0.004174307162778341\nval_loss 0.00020654850973273224\n{'min_val_epoch': 15, 'min_val_loss': -0.0028133370685127545}\n******************************\nTRAIN: \t Epoch: 17 \t Loss: -0.0020693314727395773\nTRAIN: \t Epoch: 17 \t Loss: -0.0029178180266171694\nTRAIN: \t Epoch: 17 \t Loss: -0.0035972769061724343\nTRAIN: \t Epoch: 17 \t Loss: -0.003979923436418176\nTRAIN: \t Epoch: 17 \t Loss: -0.0044754350557923315\nTRAIN: \t Epoch: 17 \t Loss: -0.004648279631510377\nTRAIN: \t Epoch: 17 \t Loss: -0.004685878753662109\nTRAIN: \t Epoch: 17 \t Loss: -0.004335981328040361\nTRAIN: \t Epoch: 17 \t Loss: -0.004113566596060991\nTRAIN: \t Epoch: 17 \t Loss: -0.004168681567534804\nTRAIN: \t Epoch: 17 \t Loss: -0.004357326056130908\nTRAIN: \t Epoch: 17 \t Loss: -0.0045607456704601645\nTRAIN: \t Epoch: 17 \t Loss: -0.004595453564364176\nTRAIN: \t Epoch: 17 \t Loss: -0.004733139283156821\nTRAIN: \t Epoch: 17 \t Loss: -0.004873867612332106\nTRAIN: \t Epoch: 17 \t Loss: -0.004880188353126869\nTRAIN: \t Epoch: 17 \t Loss: -0.0048204849461570875\nVALD: \t Epoch: 17 \t Loss: -0.0033402475528419018\nVALD: \t Epoch: 17 \t Loss: 0.0062581796664744616\nVALD: \t Epoch: 17 \t Loss: 0.002973462532584866\nVALD: \t Epoch: 17 \t Loss: 0.0008659068844281137\nVALD: \t Epoch: 17 \t Loss: 0.000891768566842349\n******************************\nEpoch: social-tag : 17\ntrain_loss -0.0048204849461570875\nval_loss 0.000891768566842349\n{'min_val_epoch': 15, 'min_val_loss': -0.0028133370685127545}\n******************************\nTRAIN: \t Epoch: 18 \t Loss: -0.005170907825231552\nTRAIN: \t Epoch: 18 \t Loss: -0.005637684371322393\nTRAIN: \t Epoch: 18 \t Loss: -0.0057384589066108065\nTRAIN: \t Epoch: 18 \t Loss: -0.0055839670822024345\nTRAIN: \t Epoch: 18 \t Loss: -0.005203979788348079\nTRAIN: \t Epoch: 18 \t Loss: -0.004957605502568185\nTRAIN: \t Epoch: 18 \t Loss: -0.004901045700535178\nTRAIN: \t Epoch: 18 \t Loss: -0.005013650719774887\nTRAIN: \t Epoch: 18 \t Loss: -0.005091936767308248\nTRAIN: \t Epoch: 18 \t Loss: -0.005122573976404965\nTRAIN: \t Epoch: 18 \t Loss: -0.005006924123418602\nTRAIN: \t Epoch: 18 \t Loss: -0.004695107403676957\nTRAIN: \t Epoch: 18 \t Loss: -0.004613972089898128\nTRAIN: \t Epoch: 18 \t Loss: -0.004656509795625295\nTRAIN: \t Epoch: 18 \t Loss: -0.004754403202484051\nTRAIN: \t Epoch: 18 \t Loss: -0.004909848736133426\nTRAIN: \t Epoch: 18 \t Loss: -0.004925427459510535\nVALD: \t Epoch: 18 \t Loss: 0.003028543433174491\nVALD: \t Epoch: 18 \t Loss: 0.01519852306228131\nVALD: \t Epoch: 18 \t Loss: 0.011481948584939042\nVALD: \t Epoch: 18 \t Loss: 0.007513286953326315\nVALD: \t Epoch: 18 \t Loss: 0.008577739573874563\n******************************\nEpoch: social-tag : 18\ntrain_loss -0.004925427459510535\nval_loss 0.008577739573874563\n{'min_val_epoch': 15, 'min_val_loss': -0.0028133370685127545}\n******************************\nTRAIN: \t Epoch: 19 \t Loss: -0.007576954085379839\nTRAIN: \t Epoch: 19 \t Loss: -0.007233646931126714\nTRAIN: \t Epoch: 19 \t Loss: -0.00637896250312527\nTRAIN: \t Epoch: 19 \t Loss: -0.0038717900752089918\nTRAIN: \t Epoch: 19 \t Loss: -0.0028966408921405674\nTRAIN: \t Epoch: 19 \t Loss: -0.0025138654940140745\nTRAIN: \t Epoch: 19 \t Loss: -0.002339678949543408\nTRAIN: \t Epoch: 19 \t Loss: -0.00236045807832852\nTRAIN: \t Epoch: 19 \t Loss: -0.002562538255006075\nTRAIN: \t Epoch: 19 \t Loss: -0.0028152987360954285\nTRAIN: \t Epoch: 19 \t Loss: -0.0030808628282763743\nTRAIN: \t Epoch: 19 \t Loss: -0.0033646934122468033\nTRAIN: \t Epoch: 19 \t Loss: -0.0034995110204013493\nTRAIN: \t Epoch: 19 \t Loss: -0.0036271290654050453\nTRAIN: \t Epoch: 19 \t Loss: -0.0037385516179104647\nTRAIN: \t Epoch: 19 \t Loss: -0.003837886266410351\nTRAIN: \t Epoch: 19 \t Loss: -0.0038595677125545826\nVALD: \t Epoch: 19 \t Loss: -0.0013543207896873355\nVALD: \t Epoch: 19 \t Loss: 0.008032319659832865\nVALD: \t Epoch: 19 \t Loss: 0.004814851252983014\nVALD: \t Epoch: 19 \t Loss: 0.001915847766213119\nVALD: \t Epoch: 19 \t Loss: 0.0020236315451702984\n******************************\nEpoch: social-tag : 19\ntrain_loss -0.0038595677125545826\nval_loss 0.0020236315451702984\n{'min_val_epoch': 15, 'min_val_loss': -0.0028133370685127545}\n******************************\nTRAIN: \t Epoch: 20 \t Loss: -0.005463938228785992\nTRAIN: \t Epoch: 20 \t Loss: -0.005959260277450085\nTRAIN: \t Epoch: 20 \t Loss: -0.005897954261551301\nTRAIN: \t Epoch: 20 \t Loss: -0.005818465957418084\nTRAIN: \t Epoch: 20 \t Loss: -0.005393972108140588\nTRAIN: \t Epoch: 20 \t Loss: -0.005200742860324681\nTRAIN: \t Epoch: 20 \t Loss: -0.005312627414241433\nTRAIN: \t Epoch: 20 \t Loss: -0.0054359173809643835\nTRAIN: \t Epoch: 20 \t Loss: -0.0056488830337507855\nTRAIN: \t Epoch: 20 \t Loss: -0.005693209753371775\nTRAIN: \t Epoch: 20 \t Loss: -0.005710930415344509\nTRAIN: \t Epoch: 20 \t Loss: -0.005441102529099832\nTRAIN: \t Epoch: 20 \t Loss: -0.005158002846516096\nTRAIN: \t Epoch: 20 \t Loss: -0.005164055952004024\nTRAIN: \t Epoch: 20 \t Loss: -0.005239697297414144\nTRAIN: \t Epoch: 20 \t Loss: -0.005335024150554091\nTRAIN: \t Epoch: 20 \t Loss: -0.005358689459245329\nVALD: \t Epoch: 20 \t Loss: -0.007425938732922077\nVALD: \t Epoch: 20 \t Loss: -0.00032624625600874424\nVALD: \t Epoch: 20 \t Loss: -0.0024203696909050145\nVALD: \t Epoch: 20 \t Loss: -0.0038770261453464627\nVALD: \t Epoch: 20 \t Loss: -0.004030187343651394\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [17:52<00:00,  1.13s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.5353839946329688  FDE: 0.7297538259587016\n**************************************************\n******************************\nEpoch: social-tag : 20\ntrain_loss -0.005358689459245329\nval_loss -0.004030187343651394\n{'min_val_epoch': 20, 'min_val_loss': -0.004030187343651394}\n******************************\nTRAIN: \t Epoch: 21 \t Loss: -0.008030049502849579\nTRAIN: \t Epoch: 21 \t Loss: -0.007336440263316035\nTRAIN: \t Epoch: 21 \t Loss: -0.007142084650695324\nTRAIN: \t Epoch: 21 \t Loss: -0.006792256026528776\nTRAIN: \t Epoch: 21 \t Loss: -0.006008280999958515\nTRAIN: \t Epoch: 21 \t Loss: -0.005772378062829375\nTRAIN: \t Epoch: 21 \t Loss: -0.005782728216477803\nTRAIN: \t Epoch: 21 \t Loss: -0.0058111813850700855\nTRAIN: \t Epoch: 21 \t Loss: -0.00588295055139396\nTRAIN: \t Epoch: 21 \t Loss: -0.006026735762134194\nTRAIN: \t Epoch: 21 \t Loss: -0.0060544799674641\nTRAIN: \t Epoch: 21 \t Loss: -0.006072615350907047\nTRAIN: \t Epoch: 21 \t Loss: -0.005810528205564389\nTRAIN: \t Epoch: 21 \t Loss: -0.005605864820868841\nTRAIN: \t Epoch: 21 \t Loss: -0.005545752045388023\nTRAIN: \t Epoch: 21 \t Loss: -0.005586789673543535\nTRAIN: \t Epoch: 21 \t Loss: -0.005621007950491988\nVALD: \t Epoch: 21 \t Loss: -0.007525616325438023\nVALD: \t Epoch: 21 \t Loss: -0.001696484163403511\nVALD: \t Epoch: 21 \t Loss: -0.00314132667457064\nVALD: \t Epoch: 21 \t Loss: -0.004398987046442926\nVALD: \t Epoch: 21 \t Loss: -0.004527773806508982\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [17:52<00:00,  1.13s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.5267908200342399  FDE: 0.6974441622957029\n**************************************************\n******************************\nEpoch: social-tag : 21\ntrain_loss -0.005621007950491988\nval_loss -0.004527773806508982\n{'min_val_epoch': 21, 'min_val_loss': -0.004527773806508982}\n******************************\nTRAIN: \t Epoch: 22 \t Loss: -0.007334271911531687\nTRAIN: \t Epoch: 22 \t Loss: -0.007265673950314522\nTRAIN: \t Epoch: 22 \t Loss: -0.007239549420773983\nTRAIN: \t Epoch: 22 \t Loss: -0.007343843230046332\nTRAIN: \t Epoch: 22 \t Loss: -0.006655598059296608\nTRAIN: \t Epoch: 22 \t Loss: -0.005692224901091929\nTRAIN: \t Epoch: 22 \t Loss: -0.0054209020371282736\nTRAIN: \t Epoch: 22 \t Loss: -0.0053799691595486365\nTRAIN: \t Epoch: 22 \t Loss: -0.0054729661787860096\nTRAIN: \t Epoch: 22 \t Loss: -0.005516820884076878\nTRAIN: \t Epoch: 22 \t Loss: -0.0056195703324523165\nTRAIN: \t Epoch: 22 \t Loss: -0.0057082772788514076\nTRAIN: \t Epoch: 22 \t Loss: -0.0057950209100874\nTRAIN: \t Epoch: 22 \t Loss: -0.005673824821964705\nTRAIN: \t Epoch: 22 \t Loss: -0.005326112253048147\nTRAIN: \t Epoch: 22 \t Loss: -0.00530058607000683\nTRAIN: \t Epoch: 22 \t Loss: -0.0053065441466279345\nVALD: \t Epoch: 22 \t Loss: -0.006836842745542526\nVALD: \t Epoch: 22 \t Loss: -0.0027102396124973893\nVALD: \t Epoch: 22 \t Loss: -0.003750023509686192\nVALD: \t Epoch: 22 \t Loss: -0.004566745075862855\nVALD: \t Epoch: 22 \t Loss: -0.004679022841858414\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [17:53<00:00,  1.13s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.5488509339056464  FDE: 0.70580472704967\n**************************************************\n******************************\nEpoch: social-tag : 22\ntrain_loss -0.0053065441466279345\nval_loss -0.004679022841858414\n{'min_val_epoch': 22, 'min_val_loss': -0.004679022841858414}\n******************************\nTRAIN: \t Epoch: 23 \t Loss: -0.00690301600843668\nTRAIN: \t Epoch: 23 \t Loss: -0.00680499873124063\nTRAIN: \t Epoch: 23 \t Loss: -0.0068361032754182816\nTRAIN: \t Epoch: 23 \t Loss: -0.0069210107903927565\nTRAIN: \t Epoch: 23 \t Loss: -0.0066384849138557914\nTRAIN: \t Epoch: 23 \t Loss: -0.005852779819785307\nTRAIN: \t Epoch: 23 \t Loss: -0.005460185647409942\nTRAIN: \t Epoch: 23 \t Loss: -0.005385512879001908\nTRAIN: \t Epoch: 23 \t Loss: -0.005497144160067869\nTRAIN: \t Epoch: 23 \t Loss: -0.005558707553427666\nTRAIN: \t Epoch: 23 \t Loss: -0.005761537309312685\nTRAIN: \t Epoch: 23 \t Loss: -0.0057694357334791375\nTRAIN: \t Epoch: 23 \t Loss: -0.0058456221147655295\nTRAIN: \t Epoch: 23 \t Loss: -0.00585711606877989\nTRAIN: \t Epoch: 23 \t Loss: -0.005766391249683996\nTRAIN: \t Epoch: 23 \t Loss: -0.005779165156127419\nTRAIN: \t Epoch: 23 \t Loss: -0.005792947633188354\nVALD: \t Epoch: 23 \t Loss: -0.006905365735292435\nVALD: \t Epoch: 23 \t Loss: 0.00017633172683417797\nVALD: \t Epoch: 23 \t Loss: -0.0015917761872212093\nVALD: \t Epoch: 23 \t Loss: -0.0033373325131833553\nVALD: \t Epoch: 23 \t Loss: -0.0034356308714398797\n******************************\nEpoch: social-tag : 23\ntrain_loss -0.005792947633188354\nval_loss -0.0034356308714398797\n{'min_val_epoch': 22, 'min_val_loss': -0.004679022841858414}\n******************************\nTRAIN: \t Epoch: 24 \t Loss: -0.007894736714661121\nTRAIN: \t Epoch: 24 \t Loss: -0.0076606785878539085\nTRAIN: \t Epoch: 24 \t Loss: -0.0073448011341194315\nTRAIN: \t Epoch: 24 \t Loss: -0.006681251456029713\nTRAIN: \t Epoch: 24 \t Loss: -0.006336431950330734\nTRAIN: \t Epoch: 24 \t Loss: -0.0064178763423115015\nTRAIN: \t Epoch: 24 \t Loss: -0.0065084645923759255\nTRAIN: \t Epoch: 24 \t Loss: -0.00656453357078135\nTRAIN: \t Epoch: 24 \t Loss: -0.006359259649697278\nTRAIN: \t Epoch: 24 \t Loss: -0.00598613559268415\nTRAIN: \t Epoch: 24 \t Loss: -0.005867424971339377\nTRAIN: \t Epoch: 24 \t Loss: -0.005927544746858378\nTRAIN: \t Epoch: 24 \t Loss: -0.005967490912343447\nTRAIN: \t Epoch: 24 \t Loss: -0.006088777944179518\nTRAIN: \t Epoch: 24 \t Loss: -0.006143621572603782\nTRAIN: \t Epoch: 24 \t Loss: -0.006140671350294724\nTRAIN: \t Epoch: 24 \t Loss: -0.006138823754181063\nVALD: \t Epoch: 24 \t Loss: 0.0012335372157394886\nVALD: \t Epoch: 24 \t Loss: 0.011562262894585729\nVALD: \t Epoch: 24 \t Loss: 0.006936562558015187\nVALD: \t Epoch: 24 \t Loss: 0.0036274781450629234\nVALD: \t Epoch: 24 \t Loss: 0.004112129728749113\n******************************\nEpoch: social-tag : 24\ntrain_loss -0.006138823754181063\nval_loss 0.004112129728749113\n{'min_val_epoch': 22, 'min_val_loss': -0.004679022841858414}\n******************************\nTRAIN: \t Epoch: 25 \t Loss: -0.007126119919121265\nTRAIN: \t Epoch: 25 \t Loss: -0.006994485622271895\nTRAIN: \t Epoch: 25 \t Loss: -0.006291688419878483\nTRAIN: \t Epoch: 25 \t Loss: -0.005457785387989134\nTRAIN: \t Epoch: 25 \t Loss: -0.005369485868141055\nTRAIN: \t Epoch: 25 \t Loss: -0.005591588288856049\nTRAIN: \t Epoch: 25 \t Loss: -0.005929195089265704\nTRAIN: \t Epoch: 25 \t Loss: -0.00618557762936689\nTRAIN: \t Epoch: 25 \t Loss: -0.006381805184193783\nTRAIN: \t Epoch: 25 \t Loss: -0.006421013385988772\nTRAIN: \t Epoch: 25 \t Loss: -0.006187868156385693\nTRAIN: \t Epoch: 25 \t Loss: -0.005887991069660832\nTRAIN: \t Epoch: 25 \t Loss: -0.005855826822181161\nTRAIN: \t Epoch: 25 \t Loss: -0.005932109580109162\nTRAIN: \t Epoch: 25 \t Loss: -0.005988035956397653\nTRAIN: \t Epoch: 25 \t Loss: -0.006122262260760181\nTRAIN: \t Epoch: 25 \t Loss: -0.006142032535491881\nVALD: \t Epoch: 25 \t Loss: 0.0016174966003745794\nVALD: \t Epoch: 25 \t Loss: 0.013027784298174083\nVALD: \t Epoch: 25 \t Loss: 0.009406715941925844\nVALD: \t Epoch: 25 \t Loss: 0.005589573993347585\nVALD: \t Epoch: 25 \t Loss: 0.006739782499817182\n******************************\nEpoch: social-tag : 25\ntrain_loss -0.006142032535491881\nval_loss 0.006739782499817182\n{'min_val_epoch': 22, 'min_val_loss': -0.004679022841858414}\n******************************\nTRAIN: \t Epoch: 26 \t Loss: -0.007839543744921684\nTRAIN: \t Epoch: 26 \t Loss: -0.007695619948208332\nTRAIN: \t Epoch: 26 \t Loss: -0.00758030591532588\nTRAIN: \t Epoch: 26 \t Loss: -0.007415277301333845\nTRAIN: \t Epoch: 26 \t Loss: -0.006774789933115244\nTRAIN: \t Epoch: 26 \t Loss: -0.006150669379470249\nTRAIN: \t Epoch: 26 \t Loss: -0.006083139783835837\nTRAIN: \t Epoch: 26 \t Loss: -0.006207274360349402\nTRAIN: \t Epoch: 26 \t Loss: -0.006298109811420242\nTRAIN: \t Epoch: 26 \t Loss: -0.006508556311018765\nTRAIN: \t Epoch: 26 \t Loss: -0.006605623226443475\nTRAIN: \t Epoch: 26 \t Loss: -0.006772210530471057\nTRAIN: \t Epoch: 26 \t Loss: -0.0068671493611943265\nTRAIN: \t Epoch: 26 \t Loss: -0.006717205895776195\nTRAIN: \t Epoch: 26 \t Loss: -0.006389378810611864\nTRAIN: \t Epoch: 26 \t Loss: -0.006368139023834374\nTRAIN: \t Epoch: 26 \t Loss: -0.006375991877505775\nVALD: \t Epoch: 26 \t Loss: -0.007586343213915825\nVALD: \t Epoch: 26 \t Loss: -0.0037120181805221364\nVALD: \t Epoch: 26 \t Loss: -0.004845207663796221\nVALD: \t Epoch: 26 \t Loss: -0.005727167088480201\nVALD: \t Epoch: 26 \t Loss: -0.0058540590740037415\n**************************************************\nNumber of samples: 20\n**************************************************\nModel being tested are: ['/kaggle/working/checkpoint/social-tag']\n**************************************************\nEvaluating model: /kaggle/working/checkpoint/social-tag\nProcessing Data .....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 947/947 [18:18<00:00,  1.16s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Testing ....\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ADE: 0.5252628102669415  FDE: 0.7080303378259996\n**************************************************\n******************************\nEpoch: social-tag : 26\ntrain_loss -0.006375991877505775\nval_loss -0.0058540590740037415\n{'min_val_epoch': 26, 'min_val_loss': -0.0058540590740037415}\n******************************\nTRAIN: \t Epoch: 27 \t Loss: -0.006694732699543238\nTRAIN: \t Epoch: 27 \t Loss: -0.006911576492711902\nTRAIN: \t Epoch: 27 \t Loss: -0.0068857986479997635\nTRAIN: \t Epoch: 27 \t Loss: -0.007026535808108747\nTRAIN: \t Epoch: 27 \t Loss: -0.00699422862380743\nTRAIN: \t Epoch: 27 \t Loss: -0.006811045963938038\nTRAIN: \t Epoch: 27 \t Loss: -0.006286323303356767\nTRAIN: \t Epoch: 27 \t Loss: -0.00618249797844328\nTRAIN: \t Epoch: 27 \t Loss: -0.006247563727406992\nTRAIN: \t Epoch: 27 \t Loss: -0.006491138436831534\nTRAIN: \t Epoch: 27 \t Loss: -0.006644757570360194\nTRAIN: \t Epoch: 27 \t Loss: -0.006729720800649375\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}